# CogniDoc Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Default provider for text generation: ollama, gemini, openai, anthropic
DEFAULT_LLM_PROVIDER=ollama

# Default provider for vision tasks (image description)
DEFAULT_VISION_PROVIDER=ollama

# =============================================================================
# API Keys (required for cloud providers)
# =============================================================================

# Google Gemini - https://aistudio.google.com/app/apikey
# GOOGLE_API_KEY=your-gemini-api-key

# OpenAI - https://platform.openai.com/api-keys
# OPENAI_API_KEY=your-openai-api-key

# Anthropic - https://console.anthropic.com/settings/keys
# ANTHROPIC_API_KEY=your-anthropic-api-key

# =============================================================================
# Ollama Configuration (local inference)
# =============================================================================

OLLAMA_HOST=http://localhost:11434
OLLAMA_LLM_MODEL=granite3.3:8b
OLLAMA_VISION_MODEL=qwen3-vl:8b-instruct
OLLAMA_EMBED_MODEL=qwen3-embedding:0.6b

# =============================================================================
# Cloud Model Names (if using cloud providers)
# =============================================================================

# Gemini
# DEFAULT_LLM_MODEL=gemini-2.0-flash
# DEFAULT_VISION_MODEL=gemini-2.0-flash

# OpenAI
# OPENAI_LLM_MODEL=gpt-4o
# OPENAI_VISION_MODEL=gpt-4o

# Anthropic
# ANTHROPIC_LLM_MODEL=claude-sonnet-4-20250514
# ANTHROPIC_VISION_MODEL=claude-sonnet-4-20250514

# =============================================================================
# Generation Parameters
# =============================================================================

LLM_TEMPERATURE=0.7
LLM_TOP_P=0.85
VISION_TEMPERATURE=0.2
VISION_TOP_P=0.85

# Context window size (tokens)
CONTEXT_WINDOW=128000

# =============================================================================
# Embedding Configuration
# =============================================================================

EMBED_MODEL=qwen3-embedding:0.6b

# =============================================================================
# Chunking Configuration
# =============================================================================

MAX_CHUNK_SIZE=512
SEMANTIC_CHUNK_BUFFER=5

# =============================================================================
# Retrieval Configuration
# =============================================================================

TOP_K_RETRIEVED_CHILDREN=10
TOP_K_RERANKED_PARENTS=5
TOP_K_REFS=3
ENABLE_RERANKING=true

# Hybrid search weight for dense vectors (0.0 = BM25 only, 1.0 = dense only)
HYBRID_DENSE_WEIGHT=0.6

# =============================================================================
# Timeouts
# =============================================================================

OLLAMA_REQUEST_TIMEOUT=180.0
