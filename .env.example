# CogniDoc - Environment Variables Template
# Copy this file to .env and fill in your values
# IMPORTANT: Never commit .env to version control!

# =============================================================================
# LLM Provider API Keys (at least one required)
# =============================================================================

# Google AI Studio (Gemini) - Default provider
# Get your key at: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=

# Anthropic Claude (optional)
# Get your key at: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# OpenAI (optional)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# =============================================================================
# Default Model Configuration
# =============================================================================

# Query pipeline (rewriting, reranking, generation)
DEFAULT_LLM_PROVIDER=gemini
DEFAULT_LLM_MODEL=gemini-3-flash-preview
LLM_TEMPERATURE=0.7
LLM_TOP_P=0.85

# Vision (image/table extraction during ingestion)
DEFAULT_VISION_PROVIDER=gemini
DEFAULT_VISION_MODEL=gemini-3-pro-preview
VISION_TEMPERATURE=0.2
VISION_TOP_P=0.85

# Ingestion LLM (entity extraction, community summaries, table descriptions)
INGESTION_LLM_MODEL=gemini-3-pro-preview

# Embeddings
EMBED_MODEL=qwen3-embedding:4b-q8_0

# =============================================================================
# Ollama Configuration (for local models)
# =============================================================================

OLLAMA_HOST=http://localhost:11434
OLLAMA_REQUEST_TIMEOUT=180

# Ollama model names (when using Ollama as provider)
OLLAMA_LLM_MODEL=granite3.3:8b
OLLAMA_VISION_MODEL=qwen3-vl:8b-instruct
OLLAMA_EMBED_MODEL=qwen3-embedding:4b-q8_0

# Document parsing (Docling via Ollama)
DOCLING_MODEL=ibm/granite-docling:258m-bf16

# Qwen3-Embedding task instruction (improves retrieval accuracy)
QWEN_EMBEDDING_TASK=Given a web search query, retrieve relevant passages that answer the query

# =============================================================================
# OpenAI Model Names (when using OpenAI as provider)
# =============================================================================

OPENAI_LLM_MODEL=gpt-4o
OPENAI_VISION_MODEL=gpt-4o

# =============================================================================
# Anthropic Model Names (when using Anthropic as provider)
# =============================================================================

ANTHROPIC_LLM_MODEL=claude-sonnet-4-20250514
ANTHROPIC_VISION_MODEL=claude-sonnet-4-20250514

# =============================================================================
# RAG Configuration
# =============================================================================

# Retrieval parameters
TOP_K_RETRIEVED_CHILDREN=10
TOP_K_RERANKED_PARENTS=5
TOP_K_REFS=5

# Hybrid search (dense + sparse BM25)
ENABLE_HYBRID_SEARCH=true
HYBRID_DENSE_WEIGHT=0.6
BM25_K1=1.5
BM25_B=0.75

# Reranking
ENABLE_RERANKING=true
ENABLE_CROSS_ENCODER=false
CROSS_ENCODER_MODEL=dengcao/Qwen3-Reranker-0.6B:F16

# Contextual compression (disabled by default)
ENABLE_CONTEXTUAL_COMPRESSION=false
COMPRESSION_MAX_TOKENS_PER_DOC=200

# =============================================================================
# Pipeline Configuration
# =============================================================================

# Chunking
MAX_CHUNK_SIZE=512
SEMANTIC_CHUNK_BUFFER=5
CHUNK_OVERLAP_PERCENTAGE=0.1

# YOLO detection
YOLO_CONFIDENCE_THRESHOLD=0.2

# Context window
CONTEXT_WINDOW=128000
MEMORY_WINDOW=64000

# =============================================================================
# Entity Resolution Configuration
# =============================================================================

ENABLE_ENTITY_RESOLUTION=true
ENTITY_RESOLUTION_SIMILARITY_THRESHOLD=0.75
ENTITY_RESOLUTION_LLM_CONFIDENCE=0.7
ENTITY_RESOLUTION_MAX_CONCURRENT=4
ENTITY_RESOLUTION_USE_LLM_DESCRIPTIONS=true
ENTITY_RESOLUTION_CACHE_ENABLED=true
ENTITY_RESOLUTION_CACHE_TTL_HOURS=24

# =============================================================================
# Checkpoint/Resume Configuration
# =============================================================================

MAX_CONSECUTIVE_QUOTA_ERRORS=5
CHECKPOINT_SAVE_INTERVAL=10

# =============================================================================
# Path Overrides (optional)
# =============================================================================

# COGNIDOC_PROJECT_DIR=/path/to/project
# COGNIDOC_DATA_DIR=/path/to/data
