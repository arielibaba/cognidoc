# Session CogniDoc - 9 janvier 2026

## RÃ©sumÃ©

Corrections majeures pour le routage agent, la dÃ©tection de langue, les questions mÃ©ta sur la base de donnÃ©es, et la **mÃ©moire conversationnelle du chatbot**.

## TÃ¢ches complÃ©tÃ©es cette session

| TÃ¢che | Fichier | Description |
|-------|---------|-------------|
| **Fix patterns meta-questions** | `complexity.py` | Patterns plus flexibles pour "combien de documents", typos inclus |
| **Fix language consistency** | `prompts/*.md` | RÃ¨gles de langue dans tous les prompts (rewrite, final_answer, agent) |
| **DatabaseStatsTool** | `agent_tools.py` | Nouvel outil pour rÃ©pondre aux mÃ©ta-questions sur la base |
| **Language detection** | `cognidoc_app.py` | DÃ©tection automatique FR/EN avec prÃ©fixes de clarification |
| **Tests E2E** | `tests/test_e2e_language_and_count.py` | 10 nouveaux tests pour patterns et langue |
| **Fix Gemini SDK** | `pyproject.toml` | Ajout dÃ©pendance `google-genai` dans extras |
| **Fix helpers TypeError** | `helpers.py` | Gestion format multimodal Gradio (list/None) |
| **Fix reranking provider** | `advanced_rag.py` | Utilisation `llm_chat()` au lieu de `ollama.Client()` |
| **Fix agent response empty** | `cognidoc_app.py` | Capture correcte du retour du gÃ©nÃ©rateur `run_streaming()` |
| **Fix chatbot memory** | `agent.py`, `cognidoc_app.py`, `helpers.py` | MÃ©moire conversationnelle fonctionnelle |
| **Fix DatabaseStatsTool list_documents** | `agent_tools.py` | Retourne les noms des documents avec `list_documents=True` |

## Modifications clÃ©s

### 1. Patterns DATABASE_META_PATTERNS (`complexity.py`)

Patterns plus robustes pour dÃ©tecter les questions sur la base :

```python
DATABASE_META_PATTERNS = [
    # French patterns - flexible matching
    r"\bcombien de doc",      # "combien de documents", typos
    r"\bcombien.{0,20}base\b", # "combien...base" avec 20 chars max
    r"\bbase.{0,15}comprend",  # "cette base comprend", "la base comprend-elle"
    r"\bbase.{0,15}contient",  # "la base contient"
    ...
]
```

### 2. DatabaseStatsTool (`agent_tools.py`)

Nouvel outil (9e outil) pour rÃ©pondre aux questions sur la base :

```python
class DatabaseStatsTool(BaseTool):
    name = ToolName.DATABASE_STATS
    # Retourne: total_documents, total_chunks, graph_nodes, graph_edges
```

### 3. DÃ©tection de langue (`cognidoc_app.py`)

```python
def detect_query_language(query: str) -> str:
    """DÃ©tecte FR ou EN basÃ© sur indicateurs linguistiques."""
    french_indicators = [" est ", " sont ", " que ", ...]
    ...

def get_clarification_prefix(lang: str) -> str:
    if lang == "fr":
        return "**Clarification requise :**"
    return "**Clarification needed:**"
```

### 4. RÃ¨gles de langue dans les prompts

Tous les prompts incluent maintenant :

```markdown
## Language Rules
- ALWAYS respond in the SAME LANGUAGE as the user's question.
- If the user asks in French, respond in French.
- If the user asks in English, respond in English.
```

### 5. MÃ©moire conversationnelle (`cognidoc_app.py`, `agent.py`, `helpers.py`)

La mÃ©moire du chatbot fonctionne maintenant correctement :

```
User: "Combien de documents cette base comprend-elle?"
Bot:  "Cette base de donnÃ©es comprend 5 documents."

User: "cite-les-moi"
Bot:  "Cette base de donnÃ©es comprend les 5 documents suivants: test_document, Rapport SÃ©mantique, ..."
```

**Flux corrigÃ©:**
1. Query rewriter transforme "cite-les-moi" â†’ "Cite-moi les 5 documents que cette base comprend."
2. L'agent reÃ§oit la query rÃ©Ã©crite (pas le message brut)
3. DatabaseStatsTool retourne les noms des documents via `list_documents=True`

### 6. DatabaseStatsTool amÃ©liorÃ© (`agent_tools.py`)

```python
class DatabaseStatsTool(BaseTool):
    parameters = {
        "list_documents": "Set to true to get the list of document names/titles"
    }

    def execute(self, list_documents: bool = False) -> ToolResult:
        # Utilise get_all_documents() au lieu de .documents
        docs = ki.get_all_documents()
        if list_documents:
            doc_names = [doc.metadata.get('source', {}).get('document') for doc in docs]
            stats["document_names"] = sorted(list(set(doc_names)))
```

## Tests (43+ tests passent)

| Module | Tests |
|--------|-------|
| `test_agent_tools.py` | 33 |
| `test_e2e_language_and_count.py` | 10 |
| **Total validÃ©** | **43+** |

## Commandes CLI

```bash
# Lancer l'app (avec agent activÃ©)
uv run python -m cognidoc.cognidoc_app

# Sans reranking (plus rapide)
uv run python -m cognidoc.cognidoc_app --no-rerank

# Tests
uv run python -m pytest tests/ -v
```

## Configuration

```
LLM:       gemini-2.5-flash (Gemini)
Embedding: qwen3-embedding:0.6b (Ollama)
Agent:     ActivÃ© (seuil complexitÃ©: 0.55)
DatabaseStatsTool: ActivÃ© pour meta-questions
```

## Structure mise Ã  jour

```
src/cognidoc/
â”œâ”€â”€ complexity.py        # DATABASE_META_PATTERNS amÃ©liorÃ©s
â”œâ”€â”€ agent_tools.py       # 9 outils (NEW: database_stats)
â”œâ”€â”€ agent.py             # RÃ¨gles de langue dans SYSTEM_PROMPT
â”œâ”€â”€ cognidoc_app.py      # detect_query_language(), get_clarification_prefix()
â”œâ”€â”€ helpers.py           # Fix TypeError format multimodal
â””â”€â”€ prompts/
    â”œâ”€â”€ system_prompt_rewrite_query.md      # Language Preservation rules
    â””â”€â”€ system_prompt_generate_final_answer.md # Language Rules

tests/
â”œâ”€â”€ test_agent_tools.py              # 33 tests
â””â”€â”€ test_e2e_language_and_count.py   # 10 tests (NEW)
```

## Bugs corrigÃ©s

1. **Agent path non dÃ©clenchÃ©** - Patterns trop restrictifs pour "combien de documents"
2. **RÃ©ponses en anglais** - RÃ¨gles de langue manquantes dans prompts
3. **TypeError helpers.py** - Format multimodal Gradio non gÃ©rÃ©
4. **Reranking 404** - Utilisait ollama.Client() avec modÃ¨le Gemini
5. **Gemini SDK manquant** - google-genai non installÃ© dans venv
6. **RÃ©ponse agent vide** - Le gÃ©nÃ©rateur `run_streaming()` n'Ã©tait pas correctement consommÃ©, puis `run()` Ã©tait appelÃ© une seconde fois inutilement. Fix: capture du retour via `StopIteration.value`
7. **MÃ©moire chatbot cassÃ©e** - "cite-les-moi" aprÃ¨s "combien de documents" causait "que voulez-vous citer?"
   - **Cause racine**: `KeyError: '"answer"'` dans `agent.py` dÃ» aux accolades non Ã©chappÃ©es dans SYSTEM_PROMPT
   - **Fix**: `{"answer": "..."}` â†’ `{{"answer": "..."}}`
8. **Agent utilisant raw query** - L'agent recevait "cite-les-moi" au lieu de la query rÃ©Ã©crite avec contexte
   - **Fix**: `agent.run_streaming(candidates[0])` au lieu de `user_message`
9. **parse_rewritten_query incomplet** - Ne gÃ©rait que `- ` pas `* ` comme style de bullet
   - **Fix**: Ajout `elif stripped.startswith('* '):`
10. **DatabaseStatsTool sans noms de documents** - Utilisait `.documents` qui n'existe pas
    - **Fix**: Utilisation de `get_all_documents()` + extraction des mÃ©tadonnÃ©es `source.document`

## AmÃ©liorations implÃ©mentÃ©es (session 2)

### 1. Cache des rÃ©sultats d'outils (`agent_tools.py`)

```python
class ToolCache:
    """TTL-based cache for tool results."""
    TTL_CONFIG = {
        "database_stats": 300,      # 5 minutes
        "retrieve_vector": 120,     # 2 minutes
        "retrieve_graph": 120,
        "lookup_entity": 300,
        "compare_entities": 180,
    }

    @classmethod
    def get(cls, tool_name: str, **kwargs) -> Optional[Any]:
        # Check cache with MD5 hash key
        ...

    @classmethod
    def set(cls, tool_name: str, result: Any, **kwargs) -> None:
        # Store with timestamp
        ...
```

**Avantages:**
- RÃ©duit la latence pour les requÃªtes rÃ©pÃ©tÃ©es
- TTL configurable par outil
- Log cache hit/miss pour debug
- Indicateur `[cached]` dans les rÃ©sultats

### 2. Streaming granulaire dans l'UI (`cognidoc_app.py`)

```python
state_emoji = {
    AgentState.THINKING: "ğŸ¤”",
    AgentState.ACTING: "âš¡",
    AgentState.OBSERVING: "ğŸ‘ï¸",
    AgentState.REFLECTING: "ğŸ’­",
}
progress_lines.append(f"{state_emoji} {message}")
history[-1]["content"] = f"*Processing query...*\n\n{progress_display}"
yield convert_history_to_tuples(history)
```

L'utilisateur voit maintenant en temps rÃ©el:
- ğŸ¤” [Step 1/7] Analyzing query...
- ğŸ¤” Thought: I need to search for...
- âš¡ Calling retrieve_vector(query=...)
- ğŸ‘ï¸ Result [cached]: Found 5 documents...
- ğŸ’­ Analysis: The documents contain...

### 3. Prompts optimisÃ©s pour rÃ©duire les steps (`agent.py`)

**Avant:** 5-7 steps typiques
**AprÃ¨s:** 2-3 steps pour la plupart des requÃªtes

```python
SYSTEM_PROMPT = """You are an efficient research assistant. Your goal is to answer questions QUICKLY with MINIMAL steps.

## Efficiency Guidelines - CRITICAL
1. **One retrieval is usually enough.** After ONE successful retrieve_vector or retrieve_graph call, you likely have enough information. Proceed to final_answer.
2. **Skip synthesis for simple questions.** Use final_answer directly after getting relevant documents.
3. **Target: 2-3 steps max for most queries.** Complex comparisons may need 4 steps.
...
"""
```

**Changements clÃ©s:**
- SYSTEM_PROMPT plus directif et efficace
- THINK_PROMPT simplifiÃ© (encourage action immÃ©diate)
- REFLECT_PROMPT focalisÃ© sur "Can you answer NOW?"
- Instructions claires pour Ã©viter redondances

## Tests (127 tests passent)

| Module | Tests |
|--------|-------|
| `test_agent.py` | 27 |
| `test_agent_tools.py` | 33 |
| `test_complexity.py` | 24 |
| `test_e2e_language_and_count.py` | 10 |
| `test_providers.py` | 33 |
| **Total validÃ©** | **127** |

### 4. Fix langue dans le Fast Path (`user_prompt_generate_final_answer.md`)

Le fast path rÃ©pondait parfois en anglais (ex: "No relevant details are available").

**Avant:**
```markdown
- If insufficient information is available, respond clearly with:
  **"No relevant details are available."**
```

**AprÃ¨s:**
```markdown
- If insufficient information is available, respond in the user's language:
  - French: **"Je n'ai pas trouvÃ© d'informations pertinentes..."**
  - English: **"I could not find relevant information..."**
- CRITICAL: Deliver your ENTIRE response in the SAME LANGUAGE as the user's question.
```

## Commits de cette session

| Hash | Description |
|------|-------------|
| `a56ecdf` | Improve agent performance: caching, streaming, and optimized prompts |
| `0a05114` | Update SESSION_RESUME.md with performance improvements |
| `c68164f` | Fix language consistency in fast path responses |

## AmÃ©liorations implÃ©mentÃ©es (session 3)

### 1. Cache Persistant SQLite (`utils/tool_cache.py`)

Remplacement du cache mÃ©moire par un cache SQLite persistant :

```python
class PersistentToolCache:
    """SQLite-based persistent cache for tool results."""
    TTL_CONFIG = {
        "database_stats": 300,      # 5 minutes
        "retrieve_vector": 120,     # 2 minutes
        "retrieve_graph": 120,
        "lookup_entity": 300,
        "compare_entities": 180,
    }

    @classmethod
    def get(cls, tool_name: str, **kwargs) -> Optional[Any]
    @classmethod
    def set(cls, tool_name: str, result: Any, **kwargs) -> None
    @classmethod
    def cleanup_expired(cls) -> int  # Nettoie les entrÃ©es expirÃ©es
    @classmethod
    def stats(cls) -> Dict[str, Any]
```

**Avantages:**
- Persiste entre les redÃ©marrages de l'app
- MÃªme API que l'ancien ToolCache (migration transparente)
- Cleanup automatique des entrÃ©es expirÃ©es
- Stockage dans `data/cache/tool_cache.db`

### 2. MÃ©triques de Performance (`utils/metrics.py`)

Nouveau systÃ¨me de mÃ©triques avec stockage SQLite :

```python
@dataclass
class QueryMetrics:
    path: str                    # "fast", "enhanced", "agent"
    query_type: Optional[str]    # "FACTUAL", "EXPLORATORY", etc.
    complexity_score: Optional[float]
    total_time_ms: float
    rewrite_time_ms: Optional[float]
    retrieval_time_ms: Optional[float]
    rerank_time_ms: Optional[float]
    llm_time_ms: Optional[float]
    cache_hits: int = 0
    cache_misses: int = 0
    agent_steps: Optional[int] = None
    tools_used: Optional[List[str]] = None

class PerformanceMetrics:
    def log_query(self, metrics: QueryMetrics) -> None
    def get_global_stats(self) -> Dict[str, Any]
    def get_latency_by_path(self) -> List[Dict]
    def get_latency_over_time(self, hours: int = 24) -> List[Dict]
    def get_path_distribution(self) -> List[Dict]
    def get_recent_queries(self, limit: int = 20) -> List[Dict]
```

### 3. Dashboard Metrics (`cognidoc_app.py`)

Nouvel onglet "Metrics" dans l'interface Gradio avec :

| Composant | Description |
|-----------|-------------|
| **Stats globales** | Total queries, avg latency, cache hit rate, avg agent steps |
| **Latence par path** | Bar chart Plotly (agent vs fast vs enhanced) |
| **Distribution paths** | Pie chart Plotly |
| **Latence temporelle** | Line chart avec Ã©volution sur 24h |
| **Table requÃªtes** | 20 derniÃ¨res requÃªtes avec dÃ©tails |

```python
# Fonctions dashboard
def create_latency_by_path_chart() -> go.Figure
def create_path_distribution_chart() -> go.Figure
def create_latency_over_time_chart() -> go.Figure
def get_recent_queries_dataframe() -> pd.DataFrame
def get_global_stats_html() -> str
```

### 4. Fichiers modifiÃ©s/crÃ©Ã©s

| Fichier | Action |
|---------|--------|
| `src/cognidoc/utils/tool_cache.py` | **NOUVEAU** - PersistentToolCache SQLite |
| `src/cognidoc/utils/metrics.py` | **NOUVEAU** - PerformanceMetrics + QueryMetrics |
| `src/cognidoc/agent_tools.py` | Import PersistentToolCache, tracking cache hits |
| `src/cognidoc/cognidoc_app.py` | Dashboard Metrics, logging QueryMetrics |
| `src/cognidoc/constants.py` | TOOL_CACHE_DB, METRICS_DB paths |
| `pyproject.toml` | Ajout `plotly>=5.0` aux dÃ©pendances UI |

### 5. Commits session 3

| Hash | Description |
|------|-------------|
| `c2521fa` | Add persistent SQLite cache and performance metrics dashboard |
| `0a8f73c` | Fix QueryType enum serialization for SQLite metrics |
| `6eddd30` | Add plotly to UI dependencies for metrics dashboard |

### 6. Tests vÃ©rifiÃ©s

```bash
# 127 tests passent
uv run python -m pytest tests/ -v
```

| MÃ©trique | Valeur |
|----------|--------|
| Tests passÃ©s | 127 |
| Couverture cache | âœ… |
| Couverture metrics | âœ… |

### 7. Export MÃ©triques CSV/JSON (`utils/metrics.py`, `cognidoc_app.py`)

Ajout de fonctions d'export et boutons dans le dashboard :

```python
class PerformanceMetrics:
    def export_to_csv(self, filepath: Optional[str] = None) -> str:
        """Export all metrics to CSV format."""
        ...

    def export_to_json(self, filepath: Optional[str] = None) -> str:
        """Export all metrics to JSON format with global stats."""
        ...
```

**Boutons dans l'onglet Metrics:**
- ğŸ“¥ Export CSV - TÃ©lÃ©charge toutes les requÃªtes en CSV
- ğŸ“¥ Export JSON - TÃ©lÃ©charge avec stats globales incluses

**Format JSON:**
```json
{
  "exported_at": "2026-01-09T13:28:55",
  "total_records": 4,
  "global_stats": { ... },
  "queries": [ ... ]
}
```

### 8. Commits session 3 (complet)

| Hash | Description |
|------|-------------|
| `c2521fa` | Add persistent SQLite cache and performance metrics dashboard |
| `0a8f73c` | Fix QueryType enum serialization for SQLite metrics |
| `6eddd30` | Add plotly to UI dependencies for metrics dashboard |
| `1520d57` | Update SESSION_RESUME.md with session 3 changes |
| `721ebc8` | Add CSV and JSON export for metrics dashboard |

## AmÃ©liorations implÃ©mentÃ©es (session 4)

### 1. Batching Async des Embeddings (`create_embeddings.py`)

Refactoring complet pour traitement par lots avec requÃªtes concurrentes :

```python
# Nouveaux paramÃ¨tres
create_embeddings(
    chunks_dir="...",
    embeddings_dir="...",
    embed_model="qwen3-embedding:0.6b",
    batch_size=32,        # Chunks par batch
    max_concurrent=4,     # RequÃªtes HTTP simultanÃ©es
)
```

**Architecture:**
```
Phase 1: Collecte
â”œâ”€â”€ Scan des fichiers
â”œâ”€â”€ VÃ©rification cache
â””â”€â”€ Filtrage (parent chunks, fichiers courts)
         â†“
Phase 2: Batching async
â”œâ”€â”€ Batches de 32 chunks
â”œâ”€â”€ 4 requÃªtes HTTP concurrentes (asyncio + httpx)
â”œâ”€â”€ Progress bar tqdm
â””â”€â”€ Cache + Ã©criture fichiers
```

**Benchmark:** 8 textes
- SÃ©quentiel: 1.01s (126ms/texte)
- Async batch: 0.19s (24ms/texte)
- **Speedup: 5.27x**

### 2. ParallÃ©lisation PDFâ†’Images (`convert_pdf_to_image.py`)

Conversion parallÃ¨le avec ProcessPoolExecutor :

```python
convert_pdf_to_image(
    pdf_dir="data/pdfs",
    image_dir="data/images",
    dpi=600,
    max_workers=4,    # Processus parallÃ¨les
    parallel=True,
)
```

**Benchmark:** 7 PDFs, 12 pages, 150 DPI
- SÃ©quentiel: 13.63s
- ParallÃ¨le (4 workers): 1.23s
- **Speedup: 11x**

### 3. MÃ©thode embed_async() (`utils/embedding_providers.py`)

Nouvelle mÃ©thode async pour OllamaEmbeddingProvider :

```python
class OllamaEmbeddingProvider:
    async def embed_async(
        self,
        texts: List[str],
        max_concurrent: int = 4
    ) -> List[List[float]]:
        """Embed avec requÃªtes HTTP concurrentes."""
        ...
```

### 4. Fichiers modifiÃ©s

| Fichier | Action |
|---------|--------|
| `src/cognidoc/create_embeddings.py` | Refactoring complet avec batching async |
| `src/cognidoc/convert_pdf_to_image.py` | Ajout ProcessPoolExecutor + tqdm |
| `src/cognidoc/utils/embedding_providers.py` | Ajout `embed_async()` |

### 5. Fix asyncio conflict (`create_embeddings.py`)

Le pipeline async appelait `asyncio.run()` alors qu'il Ã©tait dÃ©jÃ  dans une event loop :

```python
# DÃ©tection du contexte async
try:
    loop = asyncio.get_running_loop()
    in_async_context = True
except RuntimeError:
    in_async_context = False

# Workaround: ThreadPoolExecutor pour isoler l'event loop
if in_async_context:
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(asyncio.run, embed_batch_async(...))
        success, errors = future.result()
else:
    success, errors = asyncio.run(embed_batch_async(...))
```

### 6. Commits session 4

| Hash | Description |
|------|-------------|
| `74f94ec` | Add batched async embedding generation for faster ingestion |
| `eed1313` | Add parallel PDF to image conversion for faster ingestion |
| `077202b` | Fix asyncio conflict in pipeline |

### 8. Optimisations pour M2 16GB

| ParamÃ¨tre | Valeur | Raison |
|-----------|--------|--------|
| `max_workers` (PDF) | 4 | Ã‰vite saturation mÃ©moire unifiÃ©e |
| `max_concurrent` (embed) | 4 | Overlap I/O sans surcharger Ollama |
| `batch_size` | 32 | Bon Ã©quilibre mÃ©moire/throughput |

### 9. RÃ©sultats tests pipeline

Pipeline complet exÃ©cutÃ© avec succÃ¨s :

| Ã‰tape | Temps | DÃ©tails |
|-------|-------|---------|
| **PDF â†’ Images** | ~6s | 7 PDFs, 12 pages (parallÃ¨le 4 workers) |
| **YOLO Detection** | ~17s | 17 images, 17 text regions |
| **Embedding Generation** | 0.88s | 14 nouveaux + 10 du cache |
| **Index Building** | 0.64s | 29 documents indexÃ©s |
| **Graph Extraction** | 53.6s | 24 chunks, 64 entities, 40 relations |
| **Graph Building** | 9.7s | 25 nodes, 19 edges, 11 communities |

**Tests unitaires:** 127/127 passÃ©s

## AmÃ©liorations implÃ©mentÃ©es (session 5)

### 1. Fix comptage documents sources vs chunks (`agent_tools.py`)

**ProblÃ¨me:** `DatabaseStatsTool` retournait 29 (chunks) au lieu de 2 (documents sources uniques).

**Solution:** Extraction des noms de fichiers sources depuis les mÃ©tadonnÃ©es de chaque chunk :

```python
def execute(self, list_documents: bool = False) -> ToolResult:
    """Get database statistics.

    Returns unique source document count (not chunk count).
    - total_documents: Number of unique source files (PDFs)
    - total_chunks: Number of chunks in the index
    - document_names: List of unique source document names
    """
    # Extract unique source documents from ALL chunks
    unique_sources = set()
    for doc in docs:
        source = doc.metadata.get('source', {})
        if isinstance(source, dict):
            name = source.get('document')
        # ...

    stats["total_documents"] = len(unique_sources)  # Sources uniques
    stats["total_chunks"] = len(docs)               # Chunks
```

### 2. Patterns pour listage documents (`complexity.py`)

Ajout de 12 nouveaux patterns pour dÃ©tecter les questions de listage :

```python
DATABASE_META_PATTERNS = [
    # ... existing patterns ...

    # French patterns - listing documents (NEW)
    r"\bliste[rz]?\b.*\bdoc",     # "liste les documents"
    r"\bnoms?\b.*\bdoc",          # "noms des documents"
    r"\bcite[rz]?\b.*\bdoc",      # "cite les documents"
    r"\b[eÃ©]num[eÃ¨]re[rz]?\b.*\bdoc",  # "Ã©numÃ¨re les documents"
    r"\bquels?\b.*\bdoc",         # "quels documents"
    r"\bdonne.*\bnoms?\b",        # "donne-moi les noms"

    # English patterns - listing documents (NEW)
    r"\blist\b.*\bdoc",           # "list the documents"
    r"\bnames?\b.*\bdoc",         # "names of documents"
    r"\bwhat\b.*\bdoc",           # "what documents"
    r"\bwhich\b.*\bdoc",          # "which documents"
]
```

### 3. RÃ©Ã©criture README.md

Le README a Ã©tÃ© entiÃ¨rement rÃ©Ã©crit pour plus de clartÃ© :
- Quick Start en premier (3 Ã©tapes simples)
- Suppression des redondances
- Diagrammes simplifiÃ©s
- EnchaÃ®nement logique : installer â†’ configurer â†’ utiliser â†’ comprendre
- 426 lignes supprimÃ©es, 181 ajoutÃ©es

### 4. Commits session 5

| Hash | Description |
|------|-------------|
| `a4ee039` | Fix document count to return unique sources instead of chunks |
| `65e1a61` | Update documentation with session 5 changes |
| `2a1c93f` | Rewrite README.md for clarity and logical flow |

### 5. Tests vÃ©rifiÃ©s

```bash
# 127 tests passent
.venv/bin/python -m pytest tests/ -v
```

### 6. Ã‰tat final

- **App:** Fonctionne correctement (testÃ©e avec questions sur documents)
- **DatabaseStatsTool:** Retourne 2 documents sources (pas 29 chunks)
- **Patterns listage:** 12 nouveaux patterns pour dÃ©tecter "liste les docs", "quels documents", etc.
- **Documentation:** README.md rÃ©Ã©crit, SESSION_RESUME.md et CLAUDE.md mis Ã  jour

## AmÃ©liorations implÃ©mentÃ©es (session 6)

### 1. Upgrade Gemini 2.0 â†’ 2.5 Flash

Remplacement du modÃ¨le LLM par dÃ©faut dans tout le codebase :

```python
# Avant
DEFAULT_LLM_MODEL = "gemini-2.0-flash"

# AprÃ¨s
DEFAULT_LLM_MODEL = "gemini-2.5-flash"
```

**Fichiers modifiÃ©s (11):**
- `src/cognidoc/constants.py`
- `src/cognidoc/utils/llm_providers.py`
- `src/cognidoc/utils/llm_client.py`
- `src/cognidoc/api.py`
- `.env`
- `README.md`
- `CLAUDE.md`
- Et autres fichiers de configuration

**Avantages Gemini 2.5 Flash:**
- Meilleur raisonnement (thinking tokens)
- QualitÃ© similaire avec `thinking=0`
- 20-30% moins de tokens utilisÃ©s

### 2. YOLO Batching (`extract_objects_from_image.py`)

Batch inference GPU pour amÃ©liorer l'utilisation mÃ©moire sur M2/M3 :

```python
def process_images_batch(
    self,
    image_paths: List[Path]
) -> List[Tuple[Path, np.ndarray, List[Dict], List[Dict]]]:
    """Run batch inference on multiple images for improved GPU utilization."""
    with timer(f"YOLO batch inference ({len(valid_paths)} images)"):
        batch_results = self.model(
            [str(p) for p in valid_paths],
            conf=self.conf_threshold,
            iou=self.iou_threshold,
            verbose=False
        )
```

**Nouveaux paramÃ¨tres CLI:**
```bash
--yolo-batch-size 2      # Taille des batches (dÃ©faut: 2)
--no-yolo-batching       # DÃ©sactiver le batching
```

**Gain estimÃ©:** 15-30% sur M2 16GB (marginal car MPS, pas CUDA)

### 3. Async Entity Extraction (`extract_entities.py`)

Extraction parallÃ¨le des entitÃ©s avec semaphore pour contrÃ´le de concurrence :

```python
async def extract_from_chunks_dir_async(
    chunks_dir: str = None,
    config: Optional[GraphConfig] = None,
    include_parent_chunks: bool = False,
    max_concurrent: int = 4,
    show_progress: bool = True,
) -> List[ExtractionResult]:
    """Async version with concurrent extraction using semaphore."""
    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_chunk(chunk_file: Path) -> Optional[ExtractionResult]:
        async with semaphore:
            result = await extract_from_chunk_async(...)

    tasks = [process_chunk(cf) for cf in chunk_files]
    results_raw = await async_tqdm.gather(*tasks, desc="Entity extraction")
```

**Nouveaux paramÃ¨tres CLI:**
```bash
--entity-max-concurrent 4   # RequÃªtes LLM simultanÃ©es (dÃ©faut: 4)
--no-async-extraction       # DÃ©sactiver l'extraction async
```

**Gain estimÃ©:** 2-4x speedup pour GraphRAG

### 4. json_mode pour llm_chat_async (`utils/llm_client.py`)

Support du mode JSON pour les rÃ©ponses structurÃ©es :

```python
async def llm_chat_async(
    messages: List[Dict[str, str]],
    temperature: Optional[float] = None,
    json_mode: bool = False,
) -> str:
```

### 5. TOP_K_REFS Configuration (`constants.py`)

Nouvelle constante pour afficher toutes les rÃ©fÃ©rences :

```python
TOP_K_RETRIEVED_CHILDREN = int(os.getenv("TOP_K_RETRIEVED_CHILDREN", "10"))
TOP_K_RERANKED_PARENTS = int(os.getenv("TOP_K_RERANKED_PARENTS", "5"))
# Number of references to display (defaults to TOP_K_RERANKED_PARENTS)
TOP_K_REFS = int(os.getenv("TOP_K_REFS", str(TOP_K_RERANKED_PARENTS)))
```

### 6. README pip install workflow

RÃ©Ã©criture de la section "Getting Started" pour montrer pip install comme mÃ©thode principale :

```bash
# Installation via pip (pas besoin de cloner)
pip install "cognidoc[all] @ git+https://github.com/arielibaba/cognidoc.git"

# CrÃ©er un nouveau projet
mkdir my-doc-assistant && cd my-doc-assistant
mkdir -p data/sources
```

### 7. Commits session 6

| Hash | Description |
|------|-------------|
| `9312a1e` | Add YOLO batching and async entity extraction for improved performance |
| `a22ce32` | Add detailed usage instructions and fix TOP_K_REFS default |
| `bd4d954` | Rewrite README.md for clarity and logical flow |

### 8. Tests vÃ©rifiÃ©s

```bash
# Pipeline testÃ© avec succÃ¨s sur 1 page
YOLO batching: 1 image en 1.17s âœ…
Entity extraction async: 2 chunks en parallÃ¨le âœ…
```

## AmÃ©liorations implÃ©mentÃ©es (session 7)

### 1. Suite de tests E2E pytest (`tests/test_00_e2e_pipeline.py`)

CrÃ©ation d'une suite de tests E2E rÃ©utilisable pour les futures mises Ã  jour :

```python
# Structure des tests
class TestE2EQueryOnly:           # Tests rapides sur indexes existants (~30s)
class TestE2ETestDocumentContent: # Validation du document fixture
class TestE2EFullPipeline:        # Tests complets avec ingestion (@slow)
class TestE2EEdgeCases:           # Cas limites et gestion d'erreurs
```

**Commandes:**
```bash
# Tests rapides E2E (~30s)
pytest tests/test_00_e2e_pipeline.py -v

# Tests complets avec ingestion (~2-5 min)
pytest tests/test_00_e2e_pipeline.py -v --run-slow
```

### 2. Configuration pytest (`tests/conftest.py`)

```python
def pytest_configure(config):
    config.addinivalue_line("markers", "slow: marks tests as slow")

def pytest_addoption(parser):
    parser.addoption("--run-slow", action="store_true", default=False)
```

### 3. Document fixture (`tests/fixtures/test_article.md`)

Article de test sur l'IA en mÃ©decine (franÃ§ais) utilisable pour les tests E2E.

### 4. Nettoyage fichiers obsolÃ¨tes

Suppression des anciens fichiers de test :
- `test_advanced_rag.py`
- `test_e2e 2.py`
- `test_e2e/` directory
- `test_e2e_script.py`

### 5. Fix conflit Qdrant embedded

**ProblÃ¨me:** Qdrant embedded n'autorise qu'un seul client par dossier. Quand tous les tests s'exÃ©cutaient ensemble, les tests E2E Ã©chouaient car un autre module verrouillait Qdrant.

**Solution:**
1. RenommÃ© `test_e2e_pipeline.py` â†’ `test_00_e2e_pipeline.py` (s'exÃ©cute en premier alphabÃ©tiquement)
2. AjoutÃ© fixture `cognidoc_session` session-scoped dans `conftest.py`
3. Les tests E2E partagent une seule instance CogniDoc

```python
# conftest.py - Session-scoped fixture
@pytest.fixture(scope="session")
def cognidoc_session():
    """Shared CogniDoc instance across ALL test modules."""
    global _session_cognidoc
    if _session_cognidoc is None:
        from cognidoc import CogniDoc
        _session_cognidoc = CogniDoc(...)
    return _session_cognidoc
```

### 6. Documentation API REST

Ajout de la documentation pour intÃ©grer CogniDoc depuis une autre application :

```bash
# Endpoint principal
POST http://localhost:7860/api/submit_handler

# Exemple curl
curl -X POST http://localhost:7860/api/submit_handler \
  -H "Content-Type: application/json" \
  -d '{"data": ["Question?", [], true, true]}'
```

**Endpoints disponibles:**
- `/api/submit_handler` - Poser une question
- `/api/reset_conversation` - RÃ©initialiser la conversation
- `/api/refresh_metrics` - MÃ©triques de performance
- `/api/export_csv` / `/api/export_json` - Export mÃ©triques

### 7. Commits session 7

| Hash | Description |
|------|-------------|
| `3435f36` | Add proper pytest E2E test suite for future updates |
| `9d6aa5f` | Update documentation with session 7 E2E test suite |
| `311f7c2` | Fix Qdrant lock conflict in tests |
| `5e69771` | Update docs with renamed E2E test file |
| `ba3738e` | Update documentation with Qdrant fix details |
| `11373a7` | Add API Integration documentation to README |

### 8. Tests vÃ©rifiÃ©s

```bash
# Tous les tests passent maintenant ensemble
pytest tests/ -v
# 134 passed, 2 skipped in ~27s
```

## AmÃ©liorations implÃ©mentÃ©es (session 8)

### 1. Support multilingue ES/DE (`cognidoc_app.py`)

Extension du support linguistique de FR/EN Ã  FR/EN/ES/DE :

```python
def detect_query_language(query: str) -> str:
    """
    Heuristic to detect query language.
    Returns 'es' for Spanish, 'de' for German, 'fr' for French, 'en' for English (default).
    Detection uses indicator counting - highest count wins (threshold: 2+).
    """
    spanish_indicators = [...]  # ~50 indicateurs
    german_indicators = [...]   # ~45 indicateurs
    french_indicators = [...]   # ~30 indicateurs
```

**Messages localisÃ©s:**
```python
prefixes = {
    "fr": "**Clarification requise :**",
    "es": "**Se necesita aclaraciÃ³n:**",
    "de": "**KlÃ¤rung erforderlich:**",
}

messages = {
    "fr": "Je n'ai pas trouvÃ© d'informations pertinentes...",
    "es": "No he encontrado informaciÃ³n relevante en la base documental...",
    "de": "Ich habe keine relevanten Informationen in der Dokumentenbasis gefunden...",
}
```

### 2. DATABASE_META_PATTERNS ES/DE (`complexity.py`)

Ajout de 34 nouveaux patterns pour l'espagnol et l'allemand :

**Espagnol (17 patterns):**
- `cuÃ¡ntos documentos`, `nÃºmero de documentos`, `tamaÃ±o de la base`
- `lista los documentos`, `quÃ© documentos`, `cuÃ¡les documentos`

**Allemand (17 patterns):**
- `wie viele Dokumente`, `Anzahl der Dokumente`, `GrÃ¶ÃŸe der Datenbank`
- `liste die Dokumente`, `welche Dokumente`, `zeige mir die Dokumente`

### 3. Prompts multilingues

Mise Ã  jour de 4 fichiers de prompts avec rÃ¨gles ES/DE :
- `system_prompt_generate_final_answer.md`
- `user_prompt_generate_final_answer.md`
- `system_prompt_rewrite_query.md`
- `agent.py` SYSTEM_PROMPT

### 4. Tests ES/DE (`test_e2e_language_and_count.py`)

5 nouvelles classes de test (14 nouveaux tests) :
- `TestSpanishLanguageDetection`
- `TestGermanLanguageDetection`
- `TestSpanishDatabaseMetaPatterns`
- `TestGermanDatabaseMetaPatterns`
- `TestLanguageAmbiguity`

### 5. Fichiers modifiÃ©s

| Fichier | Modifications |
|---------|---------------|
| `src/cognidoc/cognidoc_app.py` | `detect_query_language()`, `get_clarification_prefix()`, `get_no_info_message()` |
| `src/cognidoc/complexity.py` | 34 nouveaux DATABASE_META_PATTERNS ES/DE |
| `src/cognidoc/agent.py` | SYSTEM_PROMPT language rules ES/DE |
| `src/cognidoc/prompts/*.md` | 3 fichiers avec rÃ¨gles ES/DE |
| `tests/test_e2e_language_and_count.py` | 5 nouvelles classes de test |

### 6. Tests vÃ©rifiÃ©s

```bash
# 150 tests passent (14 nouveaux tests ES/DE)
pytest tests/ -v
# 148 passed, 2 skipped in ~28s
```

### 7. MODEL_SPECS avec paramÃ¨tres officiels (`constants.py`)

Ajout d'un dictionnaire centralisÃ© avec les paramÃ¨tres officiels des providers :

```python
MODEL_SPECS = {
    "gemini-2.5-flash": {
        "provider": "gemini",
        "context_window": 1_048_576,      # 1M tokens
        "max_output_tokens": 65_536,
        "default_temperature": 1.0,
        "default_top_p": 0.95,
        "supports_vision": True,
        "supports_json_mode": True,
    },
    "gpt-4o": {
        "context_window": 128_000,
        "max_output_tokens": 16_384,
        ...
    },
    "claude-sonnet-4-20250514": {
        "context_window": 200_000,
        "max_output_tokens": 64_000,
        ...
    },
    # + Anthropic, Ollama models
}
```

**Avantages:**
- ParamÃ¨tres officiels des providers (pas de valeurs arbitraires)
- `LLMConfig.from_model("gemini-2.5-flash")` charge automatiquement les specs
- Fallback gracieux pour modÃ¨les inconnus

### 8. MEMORY_WINDOW dynamique (`helpers.py`)

La mÃ©moire de conversation s'adapte maintenant au modÃ¨le LLM :

```python
def get_memory_window() -> int:
    """Returns 50% of the model's context_window."""
    client = get_llm_client()
    if client.config.context_window:
        return int(client.config.context_window * 0.5)
    return MEMORY_WINDOW  # Fallback: 64K

# Exemples:
# Gemini 2.5 Flash (1M context) â†’ 524K memory window
# GPT-4o (128K context) â†’ 64K memory window
# Claude Sonnet 4 (200K context) â†’ 100K memory window
```

### 9. Dark mode (`cognidoc_app.py`)

Toggle dans le header pour basculer entre mode clair et sombre :

- Bouton ğŸŒ™/â˜€ï¸ dans le header
- DÃ©tection automatique de la prÃ©fÃ©rence systÃ¨me
- Persistance du choix dans `localStorage`
- ~240 lignes de CSS pour le dark mode

### 10. Commits session 8

| Hash | Description |
|------|-------------|
| `541886d` | Add Spanish and German language support |
| `83951bc` | Add MODEL_SPECS with official provider parameters |
| `6b10105` | Make MEMORY_WINDOW dynamic based on LLM context_window |
| `72e852e` | Update documentation with ES/DE, MODEL_SPECS, MEMORY_WINDOW |
| `e765f00` | Add dark mode toggle to web interface |
| `07a498f` | Update documentation with dark mode feature |
| `4be2600` | Update CLAUDE.md and IMPLEMENTATION_PLAN.md with dark mode |
| `7a55da3` | Fix dark mode toggle for Gradio compatibility |

## AmÃ©liorations futures

1. ~~**Support langues additionnelles** - Espagnol, Allemand, etc.~~ âœ… Fait
2. ~~**Cache persistant** - Utiliser Redis ou SQLite pour le cache~~ âœ… Fait
3. ~~**MÃ©triques de performance** - Dashboard temps de rÃ©ponse, cache hits~~ âœ… Fait
4. **Tests de charge** - Benchmarks avec multiple requÃªtes simultanÃ©es
5. ~~**Export mÃ©triques** - CSV/JSON pour analyse externe~~ âœ… Fait
6. **Alerting** - Notifications si latence > seuil
7. ~~**ParallÃ©lisation ingestion** - PDFâ†’images, embeddings~~ âœ… Fait
8. ~~**YOLO batching** - Batch inference GPU pour dÃ©tection~~ âœ… Fait
9. ~~**Entity extraction async** - Queue LLM avec workers~~ âœ… Fait
10. **Pipeline streaming** - DÃ©marrer chunking pendant extraction (risquÃ© sur 16GB)
11. ~~**Fix document count vs chunk count**~~ âœ… Fait
12. ~~**Tests E2E rÃ©utilisables**~~ âœ… Fait
13. ~~**Documentation API REST**~~ âœ… Fait
14. ~~**MODEL_SPECS** - ParamÃ¨tres officiels des providers~~ âœ… Fait
15. ~~**MEMORY_WINDOW dynamique** - AdaptÃ© au context_window du LLM~~ âœ… Fait
16. ~~**Dark mode** - Toggle clair/sombre dans l'interface~~ âœ… Fait
17. ~~**Documentation YOLO model** - Clarifier le requirement du modÃ¨le~~ âœ… Fait
18. ~~**CohÃ©rence paths documentation/code** - data/sources partout~~ âœ… Fait

## AmÃ©liorations implÃ©mentÃ©es (session 9)

### 1. Documentation CLAUDE.md amÃ©liorÃ©e

- Ajout d'exemples d'exÃ©cution de tests individuels
- Correction des paths de modules (`src.xxx` â†’ `cognidoc.xxx`)
- Ajout section "Source Layout" expliquant la structure du package
- RÃ©organisation section Commands avec sous-sections claires

### 2. Documentation YOLO Model

Clarification que le modÃ¨le YOLO (~109 MB) n'est **pas inclus** dans le repo :

```
models/YOLOv11/yolov11x_best.pt  # Requis pour YOLO, sinon fallback
```

**Comportement:**
- ModÃ¨le prÃ©sent â†’ YOLO detection activÃ©e
- ModÃ¨le absent â†’ Fallback extraction simple page-par-page
- `--skip-yolo` â†’ DÃ©sactiver explicitement

### 3. Structure projet mise Ã  jour

Ajout de `models/` et `config/` dans la documentation :

```
your-project/
â”œâ”€â”€ .env
â”œâ”€â”€ data/sources/           # Documents source
â”œâ”€â”€ models/YOLOv11/         # ModÃ¨le YOLO (optionnel)
â”œâ”€â”€ config/graph_schema.yaml
â””â”€â”€ data/                   # GÃ©nÃ©rÃ© aprÃ¨s ingestion
```

### 4. Clarification Setup Wizards

| Commande | Type | Description |
|----------|------|-------------|
| `python -m cognidoc.setup` | **Interactif** | Wizard complet (providers, API keys, ingestion) |
| `cognidoc init --schema` | Non-interactif | Copie templates seulement |
| Schema Wizard | **Auto** | Se lance pendant `ingest()` si pas de schema |

### 5. Fix cohÃ©rence paths `data/sources`

**Documentation (README.md, CLAUDE.md):**
- `./documents` â†’ `./data/sources`
- `./docs` â†’ `./data/sources`

**Code:**
- `cli.py`: CrÃ©e `data/sources` au lieu de `data/pdfs`
- `cli.py`: Messages "Next steps" corrigÃ©s
- `api.py`: Docstring corrigÃ©e

### 6. Table CONTEXT_WINDOW / MEMORY_WINDOW

| Model | CONTEXT_WINDOW | MEMORY_WINDOW (50%) |
|-------|----------------|---------------------|
| Gemini 2.5 Flash | 1,048,576 (1M) | 524,288 |
| GPT-4o | 128,000 | 64,000 |
| Claude Sonnet 4 | 200,000 | 100,000 |
| Granite 3.3:8b | 128,000 | 64,000 |

### 7. Commits session 9

| Hash | Description |
|------|-------------|
| `3560bf8` | Improve CLAUDE.md with correct module paths and test examples |
| `e96aa30` | Document YOLO model requirement in README and CLAUDE.md |
| `306ee1b` | Add models/ directory to project structure documentation |
| `395068a` | Add CONTEXT_WINDOW and MEMORY_WINDOW values table to CLAUDE.md |
| `526feda` | Clarify setup wizards and CLI commands in documentation |
| `aed47e9` | Fix inconsistent document paths in documentation |
| `8ce25b9` | Fix inconsistent source paths in code (data/pdfs -> data/sources) |

### 8. Tests vÃ©rifiÃ©s

```bash
# 148 passed, 2 skipped in 29.33s
pytest tests/ -v
```

---

## Session 10 - 13 janvier 2026

### ProblÃ¨me corrigÃ© : Paths pointant vers le package d'installation

**SymptÃ´me:** Lorsque CogniDoc est installÃ© comme package (`pip install cognidoc`) et utilisÃ© dans un nouveau projet, toutes les commandes (`cognidoc ingest`, `cognidoc serve`) pointaient vers les rÃ©pertoires du package d'installation au lieu du rÃ©pertoire de travail courant.

**Cause racine:** Dans `constants.py`, la variable `BASE_DIR` utilisait `Path(__file__)` qui pointe vers le rÃ©pertoire d'installation du package, pas vers `Path.cwd()`.

### Modifications

| Fichier | Changement |
|---------|------------|
| `constants.py` | `BASE_DIR` utilise maintenant `Path.cwd()` au lieu de `Path(__file__)` |
| `constants.py` | `load_dotenv()` charge explicitement `.env` depuis `Path.cwd()` |
| `constants.py` | Nouvelle variable `DATA_DIR` (remplace l'ancien `BASE_DIR`) |
| `constants.py` | Support de `COGNIDOC_DATA_DIR` env var pour override |
| `graph_config.py` | Import `DATA_DIR` au lieu de `BASE_DIR` |

### Code avant/aprÃ¨s

**Avant (`constants.py`):**
```python
load_dotenv()
BASE_DIR = Path(__file__).resolve().parent.parent.parent  # Package install dir!
```

**AprÃ¨s (`constants.py`):**
```python
load_dotenv(Path.cwd() / ".env")  # Explicit cwd
PACKAGE_DIR = Path(__file__).resolve().parent  # For prompts/templates
DATA_DIR = Path(os.getenv("COGNIDOC_DATA_DIR")) if os.getenv("COGNIDOC_DATA_DIR") else Path.cwd()
BASE_DIR = DATA_DIR  # Backward compatibility alias
```

### Architecture des paths

| Variable | Utilisation | Pointe vers |
|----------|-------------|-------------|
| `PACKAGE_DIR` | Prompts, templates embarquÃ©s | Installation du package |
| `DATA_DIR` / `BASE_DIR` | DonnÃ©es utilisateur | RÃ©pertoire de travail (cwd) |
| `COGNIDOC_DATA_DIR` | Override env var | Custom directory |

### Corrections documentation supplÃ©mentaires

**README.md:**
- Structure projet: consolidÃ© `data/` en un seul rÃ©pertoire avec `sources/` Ã  l'intÃ©rieur
- RemplacÃ© `./docs/` par `./data/sources/` (Schema Wizard section, CLI Options)
- RemplacÃ© `GEMINI_API_KEY` par `GOOGLE_API_KEY` (variable principale dans le code)
- SupprimÃ© `COMPLEXITY_THRESHOLD=0.55` (variable inexistante)

**cli.py:**
- CorrigÃ© `COGNIDOC_LLM_PROVIDER` â†’ `DEFAULT_LLM_PROVIDER` dans le template `.env`

**CLAUDE.md:**
- CorrigÃ© `src/constants.py` â†’ `src/cognidoc/constants.py`
- CorrigÃ© `src/prompts/` â†’ `src/cognidoc/prompts/`
- AjoutÃ© section "Path Resolution" documentant `DATA_DIR`, `PACKAGE_DIR`, `BASE_DIR`

### Commits session 10

| Hash | Description |
|------|-------------|
| `316ae78` | Fix paths to use cwd instead of package installation directory |
| `ffceb60` | Fix path inconsistencies in README.md |
| `547588d` | Fix configuration inconsistencies in documentation and CLI |
| `aaa22a5` | Update CLAUDE.md with correct paths and DATA_DIR documentation |
| `2b31e86` | Fix path resolution: separate PROJECT_DIR and DATA_DIR |

### Fix final des chemins (commit 2b31e86)

Le problÃ¨me `COGNIDOC_DATA_DIR=./data` causait des chemins doublÃ©s (`data/data/sources`).

**Solution:** SÃ©paration des variables:

| Variable | DÃ©faut | Usage |
|----------|--------|-------|
| `PROJECT_DIR` | `cwd()` | Racine projet (models/, config/) |
| `DATA_DIR` | `PROJECT_DIR/data` | DonnÃ©es (sources/, pdfs/, etc.) |

### Variables .env corrigÃ©es

| Variable | Statut |
|----------|--------|
| `COGNIDOC_EMBEDDING_PROVIDER` | âœ“ Correct |
| `COGNIDOC_EMBEDDING_MODEL` | âœ“ Correct |
| `DEFAULT_EMBEDDING_PROVIDER` | âœ— N'existe pas |
| `DEFAULT_EMBEDDING_MODEL` | âœ— N'existe pas |
| `COMPLEXITY_THRESHOLD` | âœ— N'existe pas |
| `COGNIDOC_DATA_DIR` | Optionnel (dÃ©faut = ./data) |

### Tests vÃ©rifiÃ©s

```bash
# 148 passed, 2 skipped in 30.05s
pytest tests/ -v
```

---

## Session 11 - 13 janvier 2026

### 1. Rapport d'ingestion complet (`run_ingestion_pipeline.py`)

Ajout d'un rapport dÃ©taillÃ© affichÃ© Ã  la fin de chaque ingestion :

```
======================================================================
                    INGESTION REPORT
======================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             DOCUMENTS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Files processed                  â”‚                               1 â”‚
â”‚   Documents converted            â”‚                               1 â”‚
â”‚ PDFs converted to images         â”‚                               1 â”‚
â”‚ Total pages generated            â”‚                               2 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           YOLO DETECTION                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Images processed                 â”‚                               2 â”‚
â”‚ Text regions detected            â”‚                               2 â”‚
â”‚ Table regions detected           â”‚                               0 â”‚
â”‚ Picture regions detected         â”‚                               0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

... (Content Extraction, Chunking & Embeddings, GraphRAG, Timing)
```

**Sections du rapport:**
- **DOCUMENTS**: Fichiers traitÃ©s, PDFs copiÃ©s, documents convertis, pages gÃ©nÃ©rÃ©es
- **YOLO DETECTION**: Images traitÃ©es, rÃ©gions texte/table/picture dÃ©tectÃ©es
- **CONTENT EXTRACTION**: RÃ©gions texte extraites, tables extraites, images dÃ©crites
- **CHUNKING & EMBEDDINGS**: Child chunks, from cache, newly embedded, parent chunks
- **KNOWLEDGE GRAPH**: Chunks traitÃ©s, entitÃ©s, relations, nÅ“uds, arÃªtes, communautÃ©s, types d'entitÃ©s
- **TIMING**: DurÃ©e de chaque Ã©tape avec total formatÃ©

### 2. Fix tiktoken duplicate plugin

**ProblÃ¨me:** Erreur `ValueError: Duplicate encoding name gpt2 in tiktoken plugin tiktoken_ext.openai_public` empÃªchant le chunking.

**Cause:** Fichier dupliquÃ© `openai_public 2.py` dans le rÃ©pertoire `tiktoken_ext/` du venv.

**Solution:** Suppression du fichier dupliquÃ©.

```bash
rm ".venv/lib/python3.12/site-packages/tiktoken_ext/openai_public 2.py"
```

### 3. Fix stats embeddings dans le rapport

**ProblÃ¨me:** Le rapport affichait 0 chunks alors que des chunks Ã©taient crÃ©Ã©s.

**Cause:** Mauvaises clÃ©s utilisÃ©es pour accÃ©der aux stats de `create_embeddings()`.

**Solution:** Correction des clÃ©s dans `format_ingestion_report()`:

```python
# Avant (incorrect)
total_chunks = embed_stats.get("total_chunks", 0)
from_cache = embed_stats.get("from_cache", 0)

# AprÃ¨s (correct)
from_cache = embed_stats.get("cached", 0)
to_embed = embed_stats.get("to_embed", 0)
newly_embedded = embed_stats.get("embedded", 0)
total_chunks = from_cache + to_embed
```

### 4. Fichiers modifiÃ©s

| Fichier | Modifications |
|---------|---------------|
| `src/cognidoc/run_ingestion_pipeline.py` | `format_ingestion_report()` function + integration at pipeline end |
| `src/cognidoc/run_ingestion_pipeline.py` | Capture des stats PDF conversion |

### 5. Commits session 11

| Hash | Description |
|------|-------------|
| `fa2b1fd` | Add comprehensive ingestion report at pipeline end |
| `0bca983` | Fix tiktoken duplicate plugin and embedding stats in report |

### 6. Tests vÃ©rifiÃ©s

```bash
# Tests sur test_article.md et test_document.txt
# Pipeline complet avec GraphRAG: âœ…
# Rapport affichÃ© correctement: âœ…
# App lancÃ©e et requÃªte testÃ©e: âœ…
```

**Exemple test_document.txt:**
- 1 document â†’ 1 page â†’ 5 child chunks
- GraphRAG: 40 entitÃ©s â†’ 31 nÅ“uds, 22 arÃªtes, 14 communautÃ©s
- Temps total: 1m 37.7s
